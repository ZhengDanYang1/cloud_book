数据分片是指分布式数据库中的数据可以被复制在网络场地的各个物理数据库中。数据分片要达到三个目的：

- 分布均匀，即每台设备上的数据量要尽可能相近；
- 负载均衡，即每台设备上的请求量要尽可能相近；
- 扩缩容时产生的数据迁移尽可能少。

数据分片是通过关系代数的基本运算实现的。目前的分片有三种方式：hash方式，一致性hash（consistent hash），按照数据范围（range based）。根据具体的业务需求进行权衡选择采用哪种方式进行分片。

目前面临的一些挑战如下：

1. 如果某个物理节点宕机，如何将该物理节点负责的数据尽快的转移到其他物理节点；
2. 如果新增了物理节点，怎么从其他节点迁移数据到新节点；
3. 对于可修改的数据（即不是只能追加的数据），比如数据库数据，如果某节点数据量变大，怎么将部分数据迁移到其他负载较小的节点，及达到动态均衡的效果。
4. 元数据的管理问题：当数据分布在各个节点，那么当用户使用的时候需要知道具体的数据在哪一个节点上。因此，系统需要维护数据的元数据：即每一个数据所在的位置、状态等信息。当用户需要具体的数据时，先查询元数据，然后再去具体的节点上查询。当数据在节点之间迁移的时候，也需要更新元数据。元数据的管理节点这里称之为meta server。元数据的管理也带来了新的挑战：

- 如何抽取数据的特征（特征是分片的依据，也是用户查询数据时的key），或者支持用户自定义数据特征；
- 如何保证meta server的高性能和高可用，是单点还是复制集

5. 分片的粒度，即数据子集的大小，也是数据迁移的基本单位。粒度过粗，不利于数据均衡；粒度过细，管理、迁移成本又会比较大。

分片都是按照一定的特征值来进行，特征值应该从应用的使用场景来选取，并结合MongoDB展示了特征值（mongodb中的sharding key）对数据操作的影响。分片信息（即元数据）需要专门的服务器存储，元数据服务器是分布式存储系统的核心，因此需要提到其可用性和可靠性，为了减轻元数据服务器的压力，分布式系统中，会在其他节点缓存元数据，缓存的元数据由带来了一致性的挑战，由此引入了Lease机制。

